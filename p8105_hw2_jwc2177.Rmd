---
title: "P8105 - Homework 2"
author: "Jake W. Coldiron - jwc2177 -"
date: "4 October 2023"
output: github_document
---

Before we begin, let's initialize a few helpful libraries since we're working with .csv files and .xlsx files.


```{r Initialize Libraries, collapse = TRUE}
#Initialize Libraries

library(tidyverse)

library(readxl)
```

# I. Problem 1

This problem uses the FiveThirtyEight data; these data were gathered to create the interactive graphic on this page. In particular, we’ll use the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is to merge these into a single data frame using year and month as keys across datasets.

## i. pols-month.csv

First, clean the data in pols-month.csv:

1. Use separate() to break up the variable mon into integer variables year, month, and day;
1. replace month number with month name; 
1. create a president variable taking values gop and dem, and remove prez_dem and prez_gop; 
1. and remove the day variable.

```{r pols_month piped and cleaned}
#pols_month piped and cleaned

pols_df = read_csv("./p8105_hw2_jwc2177_data/fivethirtyeight_datasets/pols-month.csv") %>% 
  
  separate(mon, into = c("year", "month"), sep = 4) %>% 
  
  separate(month, into = c("month", "day"), sep = 4) %>% 
  
  mutate(year = as.numeric(year)) %>% 
  
  mutate(month = recode(month, "-01-" = "january", "-02-" = "february", "-03-" = "march", "-04-" = "april", "-05-" = "may", "-06-" = "june", "-07-" = "july", "-08-" = "august", "-09-" = "september", "-10-" = "october", "-11-" = "november", "-12-" = "december")) %>% 
  
  pivot_longer(
    c("prez_gop", "prez_dem"),
    names_to = "prez",
    values_to = "whitehouse"
    ) %>% 
  
  mutate(prez = recode(prez, "prez_gop" = "gop", "prez_dem" = "dem")) %>% 
  
#Apparently there was a value of 2 for the President in September 1974, October 1974, November 1974, and December 1974. This does not make sense as the US only has one President at a time. 
  
#The value is likely referring to the resignation of Richard Nixon. Immediately after Nixon resigned on 9 August 1974, his  Vice President Gerald Ford was sworn in as President. If there was going to be a value of 2 for the President, then August 1974 would make the most sense, however there is no value of 2 in August 1974 only the aforementioned months. 
  
#This doesn't make much sense. Regardless, the data was processed as given.
  
  mutate(whitehouse = recode(whitehouse, "0" = "no", "1" = "yes", "2" = "yes")) %>% 
  
  select(-day) %>% 
  
  relocate(year, month, prez, whitehouse, gov_dem, gov_gop, rep_dem, rep_gop, sen_dem, sen_gop)

pols_df
```

## ii. snp.csv

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets:

1. arrange according to year and month, 
1. and organize so that year and month are the leading columns.

```{r snp piped and cleaned}
#snp piped and cleaned

snp_df = read_csv("./p8105_hw2_jwc2177_data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year")) %>% 
  
  mutate(month = recode(month, "1" = "january", "2" = "february","3" = "march","4" = "april","5" = "may","6" = "june","7" = "july","8" = "august","9" = "september","10" = "october","11" = "november","12" = "december")) %>% 
  
  mutate(year = paste("20", year, sep = "")) %>% 
  
  mutate(year = as.numeric(year)) %>% 
  
  mutate(year = ifelse(year > 2015, year - 100, year)) %>% 
  
  select(-day) %>% 
  
  relocate(year, month, close) %>% 
  
  rename(snp_close = close)

snp_df
```


## iii. unemployment.csv

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r unemployment piped and cleaned}
#unemployment piped and cleaned

unemployment_df = read_csv("./p8105_hw2_jwc2177_data/fivethirtyeight_datasets/unemployment.csv") %>%
  
  janitor::clean_names() %>% 
  
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_percent"
  ) %>% 
  
  mutate(month = recode(month, "jan" = "january", "feb" = "february", "mar" = "march", "apr" = "april", "may" = "may", "jun" = "june", "jul" = "july", "aug" = "august", "sep" = "september", "oct" = "october", "nov" = "november", "dec" = "december"))
  

unemployment_df

```

## iv. Joining the Datasets 

Fourth, join the datasets by merging snp into pols, and merging unemployment into the result.

```{r, joining the table together}
#joining the table together
#view(five_thirty_eight)

snp_into_pol =
  left_join(pols_df, snp_df)

five_thirty_eight = 
  left_join(snp_into_pol, unemployment_df)

five_thirty_eight
```


## v. Describing the Joined Dataset 

Fifth, write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

> The pols dataset contained the political compsition of the US Federal Government, the snp dataset contaied the value of the "Standard and Poor" (S&P 500) index and the close of buisness, and the unemployment dataset contained the average unemployment. The key varibales - those that are common throughout all datasets - are year and month as this is a time sequence analysis. Using the key variable, the combined dataset correlates political compsition, the economy as measured by the S&P 500, and unemployment. This was a large dataset, with over 1644 entires ranging from 1947 to 2015, though unemployment data is not tracked until 1948 and S&P 500 value is not tracked until 1950. 

# II. Problem 2

This problem uses the Mr. Trash Wheel data set, available as an Excel file on the course website.

## i. Import and Clean Mr. Trash Wheel

Read and clean the Mr. Trash Wheel sheet:

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
* use reasonable variable names
* omit rows that do not include dumpster-specific data

```{r import and clean trash wheel data}
#import and clean trash wheel data
#view(trash_wheel_mr_df)

trash_wheel_mr_df_omit = read_excel("./p8105_hw2_jwc2177_data/202309 Trash Wheel Collection Data.xlsx", 1) %>% 
  
  mutate(id = row_number())

trash_wheel_mr_df = subset(trash_wheel_mr_df_omit, id != 585) %>% 
  
  janitor::clean_names() %>% 
  
  select(-x15, -x16, -id) %>% 
  
  mutate(month = str_to_lower(month)) %>% 
  
  separate(date, into = c("year2", "month2", "day")) %>% 
  
  select(-year2, -month2) %>% 
  
  relocate(dumpster, year, month, day) %>% 
  
  mutate(year = as.numeric(year)) %>% 
  
  mutate(trash_wheel_name = "trash_wheel_mr") %>% 
  
  relocate(trash_wheel_name) %>% 
  
  mutate(id = row_number())

trash_wheel_mr_df
```


##. ii. New Homes Powered 

The data include a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset. Update the data to include a new homes_powered variable based on this calculation.

```{r new homes powered}
#new homes powered (nhp)
#view(trash_wheel_nhp_df)

#note: Homes Powered = each ton of trash equates to on average 500 kilowatts of electricity. An average household will use 30 kilowatts per day.

trash_wheel_nhp_df = trash_wheel_mr_df %>% 
  
  mutate(weight_ton_power = weight_tons*500) %>% 
  
  mutate(homes_powered_2 = weight_ton_power/30) %>% 
  
  select(-homes_powered) %>% 
  
  rename(homes_powered = homes_powered_2) %>% 
  
  mutate(year = as.numeric(year)) %>% 

  mutate(trash_wheel_name = "trash_wheel_nhp_mr") %>% 
  
  relocate(trash_wheel_name)
  
trash_wheel_nhp_df

```

##. iii.Trash Wheel, Gwynnda, and the Trash Wheel Family

Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.

###. a. Professor Trash Wheel 
```{r professor trash wheel}
#professor trash wheel
#view(trash_wheel_prof_df)

trash_wheel_prof_df_omit = read_excel("./p8105_hw2_jwc2177_data/202309 Trash Wheel Collection Data.xlsx", 2) %>% 
  
  mutate(id = row_number())

trash_wheel_prof_df = subset(trash_wheel_prof_df_omit, id != 107) %>% 

  janitor::clean_names() %>% 
  
  mutate(month = str_to_lower(month)) %>% 
  
  separate(date, into = c("year2", "month2", "day")) %>% 
  
  select(-year2, -month2, -id) %>% 
  
  relocate(dumpster, year, month, day) %>% 
  
  mutate(year = as.numeric(year)) %>% 

  mutate(trash_wheel_name = "trash_wheel_prof") %>% 
  
  relocate(trash_wheel_name)

trash_wheel_prof_df
```

### b. Gwynnda

```{r gwynnda trash wheel}
#gwynnda trash wheel
#view(gwynnda_df)

gwynnda_df_omit = read_excel("./p8105_hw2_jwc2177_data/202309 Trash Wheel Collection Data.xlsx", 4) %>% 
  
  mutate(id = row_number())

gwynnda_df_omit_v2 = subset(gwynnda_df_omit, id != 157)

gwynnda_df = subset(gwynnda_df_omit_v2, id != 156) %>% 
  
  janitor::clean_names() %>% 
  
  mutate(month = str_to_lower(month)) %>% 
  
  separate(date, into = c("year2", "month2", "day")) %>% 
  
  select(-year2, -month2, -id)%>% 
  
  relocate(dumpster, year, month, day) %>% 
  
  mutate(year = as.numeric(year)) %>% 

  mutate(trash_wheel_name = "trash_wheel_gwynnda") %>% 
  
  relocate(trash_wheel_name)

gwynnda_df
```

### c. Trash Wheel Family

```{r trash wheel family}
#trash wheel family 
#view(mr_prof_df)
#view(trash_wheel_family_df)

mr_prof_df = 
  bind_rows(trash_wheel_nhp_df, trash_wheel_prof_df)

trash_wheel_family_df = 
  bind_rows(mr_prof_df, gwynnda_df)

trash_wheel_family_df = relocate(trash_wheel_family_df, year, month, day)

trash_wheel_family_df

#verify

tail(trash_wheel_family_df)
```


v. Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?

> There are 846 total observations in the data. The aforementioned key variables are merely year, month, and day as these are the only numbers that are ubiqitous throughout all datasets. Mr. Trash Wheel collected 216 metric tons of trash, and Gwynnda collected 16,300 butts in July 2021.


# III. Problem 3

This problem uses data collected in an observational study to understand the trajectory of Alzheimer’s disease (AD) biomarkers. Study participants were free of Mild Cognitive Impairment (MCI), a stage between the expected cognitive decline of normal aging and the more serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The study monitored the development of MCI and recorded the age of MCI onset during the follow-up period, with the last visit marking the end of follow-up. APOE4 is a variant of the apolipoprotein E gene, significantly associated with a higher risk of developing Alzheimer’s disease. The amyloid β 42/40 ratio holds significant promise for diagnosing and predicting disease outcomes. This ratio undergoes changes over time and has been linked to the manifestation of clinical symptoms of Alzheimer’s disease.

# III. Problem 3

## i. Import and Clean and Tidy Baseline

Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). 

```{r}
#view(mci_baseline_full)

mci_baseline_full = read_csv("./p8105_hw2_jwc2177_data/data_mci/MCI_baseline.csv")  
```


```{r import and clean basline data}
#import and clean basline data
#view(mci_baseline)

mci_baseline = read_csv("./p8105_hw2_jwc2177_data/data_mci/MCI_baseline.csv", skip = 1)  %>% 
  
  janitor::clean_names() %>% 
  
  rename(apoe4_carrier_status = apoe4) %>% 
  
  rename(onset_age = age_at_onset) %>% 
  
  mutate(sex = recode(sex, "0" = "female", "1" = "male")) %>% 
  
  mutate(apoe4_carrier_status = recode(apoe4_carrier_status, "0" = "noncarrier", "1" = "carrier")) %>% 
  
  mutate(id = as.numeric(id)) 
  
mci_baseline
```


## ii. Dicussion 

Discuss important steps in the import process and relevant features of the dataset. 

> It is important to tidy the data in the data import process, i.e., take the data from human-readable form to computer-readable form. This primarily involves ommiting data under certian criteria, renaming variables, recoding values, as well as pivoting and binding multiple dataframes.

1. How many participants were recruited, and of these how many develop MCI? 

> 483 participants were recurited. 

1. What is the average baseline age? What proportion of women in the study are APOE4 carriers?

> The average baseline age was 65.01. 
> The sum of sex is 272 and given 483 total paritpants, this means 56.31% were male meaning 43.69% are female. 

## i3. Import and Clean and Tidy Amyloid β

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.


```{r import and clean basline amyloid β}
#import and clean basline data
#view(mci_baseline)

mci_amyloid = read_csv("./p8105_hw2_jwc2177_data/data_mci/mci_amyloid.csv", skip = 1)  %>% 
  
  janitor::clean_names() %>% 
  
  rename(id = study_id) %>% 
  
  mutate(id = as.numeric(id)) 
  

mci_amyloid
```

## iii. Cross-Refrenceing Baseline and Amyloid β

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. 

> Yes, mci_amyloid has four more data entries than mci_baseline. mci_amyloid has 487 participants but mci_baseline has 483 participants. 

## iv. Cleaning and Combining Baseline and Amyloid β

```{r ommiting extranous rows}
#ommiting extranous rows
#view(mci_amyloid)

mci_amyloid = subset(mci_amyloid , id != 487) 

mci_amyloid = subset(mci_amyloid , id != 486) 

mci_amyloid = subset(mci_amyloid , id != 485) 

mci_amyloid = subset(mci_amyloid , id != 484) 

mci_amyloid
```

Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

```{r}

```


