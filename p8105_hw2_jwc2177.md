P8105 - Homework 2
================
Jake W. Coldiron - jwc2177 -
4 October 2023

Before we begin, let’s initialize a few helpful libraries since we’re
working with .csv files and .xlsx files.

``` r
#Initialize Libraries

library(tidyverse)
## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
## ✔ dplyr     1.1.2     ✔ readr     2.1.4
## ✔ forcats   1.0.0     ✔ stringr   1.5.0
## ✔ ggplot2   3.4.2     ✔ tibble    3.2.1
## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
## ✔ purrr     1.0.1     
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

library(readxl)
```

# I. Problem 1

This problem uses the FiveThirtyEight data; these data were gathered to
create the interactive graphic on this page. In particular, we’ll use
the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is
to merge these into a single data frame using year and month as keys
across datasets.

## i. pols-month.csv

First, clean the data in pols-month.csv:

1.  Use separate() to break up the variable mon into integer variables
    year, month, and day;
2.  replace month number with month name;
3.  create a president variable taking values gop and dem, and remove
    prez_dem and prez_gop;
4.  and remove the day variable.

``` r
#pols_month piped and cleaned

pols_df = read_csv("./p8105_hw2_jwc2177_data/fivethirtyeight_datasets/pols-month.csv") %>% 
  
  separate(mon, into = c("year", "month"), sep = 4) %>% 
  
  separate(month, into = c("month", "day"), sep = 4) %>% 
  
  mutate(year = as.numeric(year)) %>% 
  
  mutate(month = recode(month, "-01-" = "january", "-02-" = "february", "-03-" = "march", "-04-" = "april", "-05-" = "may", "-06-" = "june", "-07-" = "july", "-08-" = "august", "-09-" = "september", "-10-" = "october", "-11-" = "november", "-12-" = "december")) %>% 
  
  pivot_longer(
    c("prez_gop", "prez_dem"),
    names_to = "prez",
    values_to = "whitehouse"
    ) %>% 
  
  mutate(prez = recode(prez, "prez_gop" = "gop", "prez_dem" = "dem")) %>% 
  
#Apparently there was a value of 2 for the President in September 1974, October 1974, November 1974, and December 1974. This does not make sense as the US only has one President at a time. 
  
#The value is likely referring to the resignation of Richard Nixon. Immediately after Nixon resigned on 9 August 1974, his  Vice President Gerald Ford was sworn in as President. If there was going to be a value of 2 for the President, then August 1974 would make the most sense, however there is no value of 2 in August 1974 only the aforementioned months. 
  
#This doesn't make much sense. Regardless, the data was processed as given.
  
  mutate(whitehouse = recode(whitehouse, "0" = "no", "1" = "yes", "2" = "yes")) %>% 
  
  select(-day) %>% 
  
  relocate(year, month, prez, whitehouse, gov_dem, gov_gop, rep_dem, rep_gop, sen_dem, sen_gop)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
pols_df
```

    ## # A tibble: 1,644 × 10
    ##     year month  prez  whitehouse gov_dem gov_gop rep_dem rep_gop sen_dem sen_gop
    ##    <dbl> <chr>  <chr> <chr>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 janua… gop   no              23      23     198     253      45      51
    ##  2  1947 janua… dem   yes             23      23     198     253      45      51
    ##  3  1947 febru… gop   no              23      23     198     253      45      51
    ##  4  1947 febru… dem   yes             23      23     198     253      45      51
    ##  5  1947 march  gop   no              23      23     198     253      45      51
    ##  6  1947 march  dem   yes             23      23     198     253      45      51
    ##  7  1947 april  gop   no              23      23     198     253      45      51
    ##  8  1947 april  dem   yes             23      23     198     253      45      51
    ##  9  1947 may    gop   no              23      23     198     253      45      51
    ## 10  1947 may    dem   yes             23      23     198     253      45      51
    ## # ℹ 1,634 more rows

## ii. snp.csv

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets:

1.  arrange according to year and month,
2.  and organize so that year and month are the leading columns.

``` r
#snp piped and cleaned

snp_df = read_csv("./p8105_hw2_jwc2177_data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year")) %>% 
  
  mutate(month = recode(month, "1" = "january", "2" = "february","3" = "march","4" = "april","5" = "may","6" = "june","7" = "july","8" = "august","9" = "september","10" = "october","11" = "november","12" = "december")) %>% 
  
  mutate(year = paste("20", year, sep = "")) %>% 
  
  mutate(year = as.numeric(year)) %>% 
  
  mutate(year = ifelse(year > 2015, year - 100, year)) %>% 
  
  select(-day) %>% 
  
  relocate(year, month, close) %>% 
  
  rename(snp_close = close)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df
```

    ## # A tibble: 787 × 3
    ##     year month    snp_close
    ##    <dbl> <chr>        <dbl>
    ##  1  2015 july         2080.
    ##  2  2015 june         2063.
    ##  3  2015 may          2107.
    ##  4  2015 april        2086.
    ##  5  2015 march        2068.
    ##  6  2015 february     2104.
    ##  7  2015 january      1995.
    ##  8  2014 december     2059.
    ##  9  2014 november     2068.
    ## 10  2014 october      2018.
    ## # ℹ 777 more rows

## iii. unemployment.csv

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
#unemployment piped and cleaned

unemployment_df = read_csv("./p8105_hw2_jwc2177_data/fivethirtyeight_datasets/unemployment.csv") %>%
  
  janitor::clean_names() %>% 
  
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_percent"
  ) %>% 
  
  mutate(month = recode(month, "jan" = "january", "feb" = "february", "mar" = "march", "apr" = "april", "may" = "may", "jun" = "june", "jul" = "july", "aug" = "august", "sep" = "september", "oct" = "october", "nov" = "november", "dec" = "december"))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment_df
```

    ## # A tibble: 816 × 3
    ##     year month     unemployment_percent
    ##    <dbl> <chr>                    <dbl>
    ##  1  1948 january                    3.4
    ##  2  1948 february                   3.8
    ##  3  1948 march                      4  
    ##  4  1948 april                      3.9
    ##  5  1948 may                        3.5
    ##  6  1948 june                       3.6
    ##  7  1948 july                       3.6
    ##  8  1948 august                     3.9
    ##  9  1948 september                  3.8
    ## 10  1948 october                    3.7
    ## # ℹ 806 more rows

## iv. Joining the Datasets

Fourth, join the datasets by merging snp into pols, and merging
unemployment into the result.

``` r
#joining the table together
#view(five_thirty_eight)

snp_into_pol =
  left_join(pols_df, snp_df)
```

    ## Joining with `by = join_by(year, month)`

``` r
five_thirty_eight = 
  left_join(snp_into_pol, unemployment_df)
```

    ## Joining with `by = join_by(year, month)`

``` r
five_thirty_eight
```

    ## # A tibble: 1,644 × 12
    ##     year month  prez  whitehouse gov_dem gov_gop rep_dem rep_gop sen_dem sen_gop
    ##    <dbl> <chr>  <chr> <chr>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ##  1  1947 janua… gop   no              23      23     198     253      45      51
    ##  2  1947 janua… dem   yes             23      23     198     253      45      51
    ##  3  1947 febru… gop   no              23      23     198     253      45      51
    ##  4  1947 febru… dem   yes             23      23     198     253      45      51
    ##  5  1947 march  gop   no              23      23     198     253      45      51
    ##  6  1947 march  dem   yes             23      23     198     253      45      51
    ##  7  1947 april  gop   no              23      23     198     253      45      51
    ##  8  1947 april  dem   yes             23      23     198     253      45      51
    ##  9  1947 may    gop   no              23      23     198     253      45      51
    ## 10  1947 may    dem   yes             23      23     198     253      45      51
    ## # ℹ 1,634 more rows
    ## # ℹ 2 more variables: snp_close <dbl>, unemployment_percent <dbl>

## v. Describing the Joined Dataset

Fifth, write a short paragraph about these datasets. Explain briefly
what each dataset contained, and describe the resulting dataset
(e.g. give the dimension, range of years, and names of key variables).

> The pols dataset contained the political compsition of the US Federal
> Government, the snp dataset contaied the value of the “Standard and
> Poor” (S&P 500) index and the close of buisness, and the unemployment
> dataset contained the average unemployment. The key varibales - those
> that are common throughout all datasets - are year and month as this
> is a time sequence analysis. Using the key variable, the combined
> dataset correlates political compsition, the economy as measured by
> the S&P 500, and unemployment. This was a large dataset, with over
> 1644 entires ranging from 1947 to 2015, though unemployment data is
> not tracked until 1948 and S&P 500 value is not tracked until 1950.

# II. Problem 2

This problem uses the Mr. Trash Wheel data set, available as an Excel
file on the course website.

## i. Import and Clean Mr. Trash Wheel

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data

``` r
#import and clean trash wheel data
#view(trash_wheel_mr_df)

trash_wheel_mr_df_omit = read_excel("./p8105_hw2_jwc2177_data/202309 Trash Wheel Collection Data.xlsx", 1) %>% 
  
  mutate(id = row_number())
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
trash_wheel_mr_df = subset(trash_wheel_mr_df_omit, id != 585) %>% 
  
  janitor::clean_names() %>% 
  
  select(-x15, -x16, -id) %>% 
  
  mutate(month = str_to_lower(month)) %>% 
  
  separate(date, into = c("year2", "month2", "day")) %>% 
  
  select(-year2, -month2) %>% 
  
  relocate(dumpster, year, month, day) %>% 
  
  mutate(year = as.numeric(year)) %>% 
  
  mutate(trash_wheel_name = "trash_wheel_mr") %>% 
  
  relocate(trash_wheel_name) %>% 
  
  mutate(id = row_number())

trash_wheel_mr_df
```

    ## # A tibble: 584 × 16
    ##    trash_wheel_name dumpster  year month day   weight_tons volume_cubic_yards
    ##    <chr>               <dbl> <dbl> <chr> <chr>       <dbl>              <dbl>
    ##  1 trash_wheel_mr          1  2014 may   16           4.31                 18
    ##  2 trash_wheel_mr          2  2014 may   16           2.74                 13
    ##  3 trash_wheel_mr          3  2014 may   16           3.45                 15
    ##  4 trash_wheel_mr          4  2014 may   17           3.1                  15
    ##  5 trash_wheel_mr          5  2014 may   17           4.06                 18
    ##  6 trash_wheel_mr          6  2014 may   20           2.71                 13
    ##  7 trash_wheel_mr          7  2014 may   21           1.91                  8
    ##  8 trash_wheel_mr          8  2014 may   28           3.7                  16
    ##  9 trash_wheel_mr          9  2014 june  05           2.52                 14
    ## 10 trash_wheel_mr         10  2014 june  11           3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, id <int>

\##. ii. New Homes Powered

The data include a column for the (approximate) number of homes powered.
This calculation is described in the Homes powered note, but not applied
to every row in the dataset. Update the data to include a new
homes_powered variable based on this calculation.

``` r
#new homes powered (nhp)
#view(trash_wheel_nhp_df)

#note: Homes Powered = each ton of trash equates to on average 500 kilowatts of electricity. An average household will use 30 kilowatts per day.

trash_wheel_nhp_df = trash_wheel_mr_df %>% 
  
  mutate(weight_ton_power = weight_tons*500) %>% 
  
  mutate(homes_powered_2 = weight_ton_power/30) %>% 
  
  select(-homes_powered) %>% 
  
  rename(homes_powered = homes_powered_2) %>% 
  
  mutate(year = as.numeric(year)) %>% 

  mutate(trash_wheel_name = "trash_wheel_nhp_mr") %>% 
  
  relocate(trash_wheel_name)
  
trash_wheel_nhp_df
```

    ## # A tibble: 584 × 17
    ##    trash_wheel_name   dumpster  year month day   weight_tons volume_cubic_yards
    ##    <chr>                 <dbl> <dbl> <chr> <chr>       <dbl>              <dbl>
    ##  1 trash_wheel_nhp_mr        1  2014 may   16           4.31                 18
    ##  2 trash_wheel_nhp_mr        2  2014 may   16           2.74                 13
    ##  3 trash_wheel_nhp_mr        3  2014 may   16           3.45                 15
    ##  4 trash_wheel_nhp_mr        4  2014 may   17           3.1                  15
    ##  5 trash_wheel_nhp_mr        5  2014 may   17           4.06                 18
    ##  6 trash_wheel_nhp_mr        6  2014 may   20           2.71                 13
    ##  7 trash_wheel_nhp_mr        7  2014 may   21           1.91                  8
    ##  8 trash_wheel_nhp_mr        8  2014 may   28           3.7                  16
    ##  9 trash_wheel_nhp_mr        9  2014 june  05           2.52                 14
    ## 10 trash_wheel_nhp_mr       10  2014 june  11           3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 10 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, id <int>, weight_ton_power <dbl>,
    ## #   homes_powered <dbl>

\##. iii.Trash Wheel, Gwynnda, and the Trash Wheel Family

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

\###. a. Professor Trash Wheel

``` r
#professor trash wheel
#view(trash_wheel_prof_df)

trash_wheel_prof_df_omit = read_excel("./p8105_hw2_jwc2177_data/202309 Trash Wheel Collection Data.xlsx", 2) %>% 
  
  mutate(id = row_number())

trash_wheel_prof_df = subset(trash_wheel_prof_df_omit, id != 107) %>% 

  janitor::clean_names() %>% 
  
  mutate(month = str_to_lower(month)) %>% 
  
  separate(date, into = c("year2", "month2", "day")) %>% 
  
  select(-year2, -month2, -id) %>% 
  
  relocate(dumpster, year, month, day) %>% 
  
  mutate(year = as.numeric(year)) %>% 

  mutate(trash_wheel_name = "trash_wheel_prof") %>% 
  
  relocate(trash_wheel_name)

trash_wheel_prof_df
```

    ## # A tibble: 106 × 14
    ##    trash_wheel_name dumpster  year month    day   weight_tons volume_cubic_yards
    ##    <chr>               <dbl> <dbl> <chr>    <chr>       <dbl>              <dbl>
    ##  1 trash_wheel_prof        1  2017 january  02           1.79                 15
    ##  2 trash_wheel_prof        2  2017 january  30           1.58                 15
    ##  3 trash_wheel_prof        3  2017 february 26           2.32                 18
    ##  4 trash_wheel_prof        4  2017 february 26           3.72                 15
    ##  5 trash_wheel_prof        5  2017 february 28           1.45                 15
    ##  6 trash_wheel_prof        6  2017 march    30           1.71                 15
    ##  7 trash_wheel_prof        7  2017 april    01           1.82                 15
    ##  8 trash_wheel_prof        8  2017 april    20           2.37                 15
    ##  9 trash_wheel_prof        9  2017 may      10           2.64                 15
    ## 10 trash_wheel_prof       10  2017 may      26           2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

### b. Gwynnda

``` r
#gwynnda trash wheel
#view(gwynnda_df)

gwynnda_df_omit = read_excel("./p8105_hw2_jwc2177_data/202309 Trash Wheel Collection Data.xlsx", 4) %>% 
  
  mutate(id = row_number())

gwynnda_df_omit_v2 = subset(gwynnda_df_omit, id != 157)

gwynnda_df = subset(gwynnda_df_omit_v2, id != 156) %>% 
  
  janitor::clean_names() %>% 
  
  mutate(month = str_to_lower(month)) %>% 
  
  separate(date, into = c("year2", "month2", "day")) %>% 
  
  select(-year2, -month2, -id)%>% 
  
  relocate(dumpster, year, month, day) %>% 
  
  mutate(year = as.numeric(year)) %>% 

  mutate(trash_wheel_name = "trash_wheel_gwynnda") %>% 
  
  relocate(trash_wheel_name)

gwynnda_df
```

    ## # A tibble: 155 × 13
    ##    trash_wheel_name    dumpster  year month day   weight_tons volume_cubic_yards
    ##    <chr>                  <dbl> <dbl> <chr> <chr>       <dbl>              <dbl>
    ##  1 trash_wheel_gwynnda        1  2021 july  03           0.93                 15
    ##  2 trash_wheel_gwynnda        2  2021 july  07           2.26                 15
    ##  3 trash_wheel_gwynnda        3  2021 july  07           1.62                 15
    ##  4 trash_wheel_gwynnda        4  2021 july  16           1.76                 15
    ##  5 trash_wheel_gwynnda        5  2021 july  30           1.53                 15
    ##  6 trash_wheel_gwynnda        6  2021 augu… 11           2.06                 15
    ##  7 trash_wheel_gwynnda        7  2021 augu… 14           1.9                  15
    ##  8 trash_wheel_gwynnda        8  2021 augu… 16           2.16                 15
    ##  9 trash_wheel_gwynnda        9  2021 augu… 16           2.6                  15
    ## 10 trash_wheel_gwynnda       10  2021 augu… 17           3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

### c. Trash Wheel Family

``` r
#trash wheel family 
#view(mr_prof_df)
#view(trash_wheel_family_df)

mr_prof_df = 
  bind_rows(trash_wheel_nhp_df, trash_wheel_prof_df)

trash_wheel_family_df = 
  bind_rows(mr_prof_df, gwynnda_df)

trash_wheel_family_df = relocate(trash_wheel_family_df, year, month, day)

trash_wheel_family_df
```

    ## # A tibble: 845 × 17
    ##     year month day   trash_wheel_name   dumpster weight_tons volume_cubic_yards
    ##    <dbl> <chr> <chr> <chr>                 <dbl>       <dbl>              <dbl>
    ##  1  2014 may   16    trash_wheel_nhp_mr        1        4.31                 18
    ##  2  2014 may   16    trash_wheel_nhp_mr        2        2.74                 13
    ##  3  2014 may   16    trash_wheel_nhp_mr        3        3.45                 15
    ##  4  2014 may   17    trash_wheel_nhp_mr        4        3.1                  15
    ##  5  2014 may   17    trash_wheel_nhp_mr        5        4.06                 18
    ##  6  2014 may   20    trash_wheel_nhp_mr        6        2.71                 13
    ##  7  2014 may   21    trash_wheel_nhp_mr        7        1.91                  8
    ##  8  2014 may   28    trash_wheel_nhp_mr        8        3.7                  16
    ##  9  2014 june  05    trash_wheel_nhp_mr        9        2.52                 14
    ## 10  2014 june  11    trash_wheel_nhp_mr       10        3.76                 18
    ## # ℹ 835 more rows
    ## # ℹ 10 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, id <int>, weight_ton_power <dbl>,
    ## #   homes_powered <dbl>

``` r
#verify

tail(trash_wheel_family_df)
```

    ## # A tibble: 6 × 17
    ##    year month day   trash_wheel_name    dumpster weight_tons volume_cubic_yards
    ##   <dbl> <chr> <chr> <chr>                  <dbl>       <dbl>              <dbl>
    ## 1  2023 june  28    trash_wheel_gwynnda      149        2.68                 15
    ## 2  2023 june  29    trash_wheel_gwynnda      150        2.74                 15
    ## 3  2023 june  29    trash_wheel_gwynnda      151        3.12                 15
    ## 4  2023 june  29    trash_wheel_gwynnda      152        3.12                 15
    ## 5  2023 june  29    trash_wheel_gwynnda      153        3.45                 15
    ## 6  2023 june  30    trash_wheel_gwynnda      154        2.88                 15
    ## # ℹ 10 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, id <int>, weight_ton_power <dbl>,
    ## #   homes_powered <dbl>

22. Write a paragraph about these data; you are encouraged to use
    inline R. Be sure to note the number of observations in the
    resulting dataset, and give examples of key variables. For available
    data, what was the total weight of trash collected by Professor
    Trash Wheel? What was the total number of cigarette butts collected
    by Gwynnda in July of 2021?

> There are 846 total observations in the data. The aforementioned key
> variables are merely year, month, and day as these are the only
> numbers that are ubiqitous throughout all datasets. Mr. Trash Wheel
> collected 216 metric tons of trash, and Gwynnda collected 16,300 butts
> in July 2021.

# III. Problem 3

This problem uses data collected in an observational study to understand
the trajectory of Alzheimer’s disease (AD) biomarkers. Study
participants were free of Mild Cognitive Impairment (MCI), a stage
between the expected cognitive decline of normal aging and the more
serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The
study monitored the development of MCI and recorded the age of MCI onset
during the follow-up period, with the last visit marking the end of
follow-up. APOE4 is a variant of the apolipoprotein E gene,
significantly associated with a higher risk of developing Alzheimer’s
disease. The amyloid β 42/40 ratio holds significant promise for
diagnosing and predicting disease outcomes. This ratio undergoes changes
over time and has been linked to the manifestation of clinical symptoms
of Alzheimer’s disease.

# III. Problem 3

## i. Import and Clean and Tidy Baseline

Import, clean, and tidy the dataset of baseline demographics. Ensure
that sex and APOE4 carrier status are appropriate encoded (i.e. not
numeric), and remove any participants who do not meet the stated
inclusion criteria (i.e. no MCI at baseline).

``` r
#view(mci_baseline_full)

mci_baseline_full = read_csv("./p8105_hw2_jwc2177_data/data_mci/MCI_baseline.csv")  
```

    ## New names:
    ## Rows: 484 Columns: 6
    ## ── Column specification
    ## ──────────────────────────────────────────────────────── Delimiter: "," chr
    ## (6): ...1, Age at the study baseline, 1 = Male, 0 = Female, Years of edu...
    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ
    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## • `` -> `...1`

``` r
#import and clean basline data
#view(mci_baseline)

mci_baseline = read_csv("./p8105_hw2_jwc2177_data/data_mci/MCI_baseline.csv", skip = 1)  %>% 
  
  janitor::clean_names() %>% 
  
  rename(apoe4_carrier_status = apoe4) %>% 
  
  rename(onset_age = age_at_onset) %>% 
  
  mutate(sex = recode(sex, "0" = "female", "1" = "male")) %>% 
  
  mutate(apoe4_carrier_status = recode(apoe4_carrier_status, "0" = "noncarrier", "1" = "carrier")) %>% 
  
  mutate(id = as.numeric(id)) 
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
mci_baseline
```

    ## # A tibble: 483 × 6
    ##       id current_age sex    education apoe4_carrier_status onset_age
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>                <chr>    
    ##  1     1        63.1 female        16 carrier              .        
    ##  2     2        65.6 female        20 carrier              .        
    ##  3     3        62.5 male          16 carrier              66.8     
    ##  4     4        69.8 female        16 noncarrier           .        
    ##  5     5        66   male          16 noncarrier           68.7     
    ##  6     6        62.5 male          16 noncarrier           .        
    ##  7     7        66.5 male          18 noncarrier           74       
    ##  8     8        67.2 female        18 noncarrier           .        
    ##  9     9        66.7 female        16 noncarrier           .        
    ## 10    10        64.1 female        18 noncarrier           .        
    ## # ℹ 473 more rows

## ii. Dicussion

Discuss important steps in the import process and relevant features of
the dataset.

> It is important to tidy the data in the data import process, i.e.,
> take the data from human-readable form to computer-readable form. This
> primarily involves ommiting data under certian criteria, renaming
> variables, recoding values, as well as pivoting and binding multiple
> dataframes.

1.  How many participants were recruited, and of these how many develop
    MCI?

> 483 participants were recurited.

1.  What is the average baseline age? What proportion of women in the
    study are APOE4 carriers?

> The average baseline age was 65.01. The sum of sex is 272 and given
> 483 total paritpants, this means 56.31% were male meaning 43.69% are
> female.

## i3. Import and Clean and Tidy Amyloid β

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

``` r
#import and clean basline data
#view(mci_baseline)

mci_amyloid = read_csv("./p8105_hw2_jwc2177_data/data_mci/mci_amyloid.csv", skip = 1)  %>% 
  
  janitor::clean_names() %>% 
  
  rename(id = study_id) %>% 
  
  mutate(id = as.numeric(id)) 
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
mci_amyloid
```

    ## # A tibble: 487 × 6
    ##       id baseline    time_2      time_4      time_6      time_8     
    ##    <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1     1 0.1105487   <NA>        0.109325197 0.104756131 0.107257697
    ##  2     2 0.107481183 0.109157373 0.109457839 0.105729713 0.10661845 
    ##  3     3 0.106087034 0.108744509 0.106065035 <NA>        0.106152357
    ##  4     4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ##  5     5 0.107950408 0.112273883 0.115139677 0.106606054 0.106052066
    ##  6     6 0.112426974 0.112853415 0.11143945  0.110279277 0.114982747
    ##  7     7 0.112246391 <NA>        0.104251905 0.112485583 0.112055612
    ##  8     8 0.109563372 0.109470828 <NA>        0.108742168 0.110268552
    ##  9     9 0.112101884 0.109781199 0.108832888 <NA>        <NA>       
    ## 10    10 0.1116094   0.111592149 <NA>        <NA>        0.110051296
    ## # ℹ 477 more rows

## iii. Cross-Refrenceing Baseline and Amyloid β

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings.

> Yes, mci_amyloid has four more data entries than mci_baseline.
> mci_amyloid has 487 participants but mci_baseline has 483
> participants.

## iv. Cleaning and Combining Baseline and Amyloid β

``` r
#ommiting extranous rows
#view(mci_amyloid)

mci_amyloid = subset(mci_amyloid , id != 487) 

mci_amyloid = subset(mci_amyloid , id != 486) 

mci_amyloid = subset(mci_amyloid , id != 485) 

mci_amyloid = subset(mci_amyloid , id != 484) 

mci_amyloid
```

    ## # A tibble: 483 × 6
    ##       id baseline    time_2      time_4      time_6      time_8     
    ##    <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1     1 0.1105487   <NA>        0.109325197 0.104756131 0.107257697
    ##  2     2 0.107481183 0.109157373 0.109457839 0.105729713 0.10661845 
    ##  3     3 0.106087034 0.108744509 0.106065035 <NA>        0.106152357
    ##  4     4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ##  5     5 0.107950408 0.112273883 0.115139677 0.106606054 0.106052066
    ##  6     6 0.112426974 0.112853415 0.11143945  0.110279277 0.114982747
    ##  7     7 0.112246391 <NA>        0.104251905 0.112485583 0.112055612
    ##  8     8 0.109563372 0.109470828 <NA>        0.108742168 0.110268552
    ##  9     9 0.112101884 0.109781199 0.108832888 <NA>        <NA>       
    ## 10    10 0.1116094   0.111592149 <NA>        <NA>        0.110051296
    ## # ℹ 473 more rows

Combine the demographic and biomarker datasets so that only participants
who appear in both datasets are retained, and briefly describe the
resulting dataset; export the result as a CSV to your data directory.
